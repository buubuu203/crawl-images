{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests) (2023.11.17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\python312\\lib\\site-packages (4.18.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\python312\\lib\\site-packages (from selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\python312\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\python312\\lib\\site-packages (from selenium) (2023.11.17)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\python312\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.16.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\python312\\lib\\site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bb\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bb\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install selenium\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl captions and images from https://www.reddit.com/r/progresspics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python312\\Lib\\socket.py:837\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    836\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 837\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m         captions\u001b[38;5;241m.\u001b[39mappend(caption)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Close the web browser\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Create a DataFrame\u001b[39;00m\n\u001b[0;32m     79\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage_Name\u001b[39m\u001b[38;5;124m'\u001b[39m: image_names, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCaption\u001b[39m\u001b[38;5;124m'\u001b[39m: captions})\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:188\u001b[0m, in \u001b[0;36mChromiumDriver.quit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:146\u001b[0m, in \u001b[0;36mService.stop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_remote_shutdown_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:131\u001b[0m, in \u001b[0;36mService.send_remote_shutdown_command\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    132\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    133\u001b[0m     sleep(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\service.py:120\u001b[0m, in \u001b[0;36mService.is_connectable\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_connectable\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Establishes a socket connection to determine if the service running\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03m    on the port is accessible.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_connectable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\selenium\\webdriver\\common\\utils.py:101\u001b[0m, in \u001b[0;36mis_connectable\u001b[1;34m(port, host)\u001b[0m\n\u001b[0;32m     99\u001b[0m socket_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     socket_ \u001b[38;5;241m=\u001b[39m \u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _is_connectable_exceptions:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\socket.py:844\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m error \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 844\u001b[0m         \u001b[43mexceptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# raise only the last error\u001b[39;00m\n\u001b[0;32m    845\u001b[0m     exceptions\u001b[38;5;241m.\u001b[39mappend(exc)\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create a directory to store images\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Function to download an image from URL and save it to the directory\n",
    "def download_image(url, filename, directory):\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(directory, filename), 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Initialize the Selenium web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the Reddit page\n",
    "url = \"https://www.reddit.com/r/progresspics/\"\n",
    "\n",
    "# Open the web page using Selenium web driver\n",
    "driver.get(url)\n",
    "\n",
    "# Function to scroll down the page to load more images\n",
    "def scroll_down_page(driver):\n",
    "    # Scroll down to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # Wait for 2 seconds after scrolling\n",
    "\n",
    "# Scroll down the page multiple times to load more images\n",
    "while True:  \n",
    "    # Get the initial height of the webpage\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    # Scroll down the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait for the new images to load\n",
    "    time.sleep(2)\n",
    "    # Calculate new height and compare with last height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break  # If no more images are loaded, exit the loop\n",
    "    last_height = new_height\n",
    "\n",
    "# Use BeautifulSoup to parse HTML after the page has loaded completely\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Find all 'img' tags in HTML\n",
    "image_tags = soup.find_all('img', class_='media-lightbox-img')\n",
    "\n",
    "# Find all post titles and their corresponding URLs\n",
    "post_links = soup.find_all('a', slot='title')\n",
    "\n",
    "# Directory to store images\n",
    "image_directory = 'progress_pics'\n",
    "create_directory(image_directory)\n",
    "\n",
    "# Lists to store image URLs and captions\n",
    "image_names = []\n",
    "captions = []\n",
    "\n",
    "# Loop through each 'img' tag to get the URL and download the image\n",
    "for i, (tag, post_link) in enumerate(zip(image_tags, post_links)):\n",
    "    if 'src' in tag.attrs:  # Check if the 'src' attribute exists\n",
    "        img_url = tag['src']\n",
    "        img_name = f\"image_{i+1}.jpg\"  # Assign a unique name to each image\n",
    "        download_image(img_url, img_name, image_directory)\n",
    "        image_names.append(img_name)\n",
    "        caption = post_link.text.strip()  # Get the text of the post link (caption)\n",
    "        captions.append(caption)\n",
    "\n",
    "# Close the web browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Image_Name': image_names, 'Caption': captions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('image_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl captions and images from https://www.reddit.com/r/progresspics/search/?q=F&type=link&cId=857c3e1c-67e4-4d52-b1be-070dac965979&iId=f9ce14d0-f25f-4ec8-8acc-3bfec57647ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to create a directory to store images\n",
    "def create_directory(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# Function to download an image from URL and save it to the directory\n",
    "def download_image(url, filename, directory):\n",
    "    response = requests.get(url)\n",
    "    with open(os.path.join(directory, filename), 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# Initialize the Selenium web driver\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# URL of the Reddit page\n",
    "url = \"https://www.reddit.com/r/progresspics/\"\n",
    "\n",
    "# Open the web page using Selenium web driver\n",
    "driver.get(url)\n",
    "\n",
    "# Function to scroll down the page to load more images\n",
    "def scroll_down_page(driver):\n",
    "    # Scroll down to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)  # Wait for 2 seconds after scrolling\n",
    "\n",
    "# Scroll down the page multiple times to load more images\n",
    "while True:  \n",
    "    # Get the initial height of the webpage\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    # Scroll down the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    # Wait for the new images to load\n",
    "    time.sleep(2)\n",
    "    # Calculate new height and compare with last height\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break  # If no more images are loaded, exit the loop\n",
    "    last_height = new_height\n",
    "\n",
    "# Use BeautifulSoup to parse HTML after the page has loaded completely\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "# Find all 'img' tags in HTML\n",
    "image_tags = soup.find_all('img', class_='media-lightbox-img')\n",
    "\n",
    "# Find all post titles and their corresponding URLs\n",
    "post_links = soup.find_all('a', slot='title')\n",
    "\n",
    "# Directory to store images\n",
    "image_directory = 'progress_pics'\n",
    "create_directory(image_directory)\n",
    "\n",
    "# Lists to store image URLs and captions\n",
    "image_names = []\n",
    "captions = []\n",
    "\n",
    "# Loop through each 'img' tag to get the URL and download the image\n",
    "for i, (tag, post_link) in enumerate(zip(image_tags, post_links)):\n",
    "    if 'src' in tag.attrs:  # Check if the 'src' attribute exists\n",
    "        img_url = tag['src']\n",
    "        img_name = f\"image_{i+1}.jpg\"  # Assign a unique name to each image\n",
    "        download_image(img_url, img_name, image_directory)\n",
    "        image_names.append(img_name)\n",
    "        caption = post_link.text.strip()  # Get the text of the post link (caption)\n",
    "        captions.append(caption)\n",
    "\n",
    "# Close the web browser\n",
    "driver.quit()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Image_Name': image_names, 'Caption': captions})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('image_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split captions into Sex, Age, Height and Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('image_data.csv')\n",
    "\n",
    "# Function to extract gender from caption\n",
    "def extract_gender(caption):\n",
    "    return caption.split('/')[0]\n",
    "\n",
    "# Function to extract age from caption\n",
    "def extract_age(caption):\n",
    "    return caption.split('/')[1].split(' ')[0]\n",
    "\n",
    "def extract_height(caption):\n",
    "    parts = caption.split('/')\n",
    "    if len(parts) > 2:\n",
    "        height_str = parts[2].strip().split('[')[0].split()[0]  # Lấy phần tử đầu tiên sau khi split theo khoảng trắng và trước dấu '['\n",
    "        return height_str\n",
    "    return None\n",
    "\n",
    "\n",
    "# Function to extract weight from caption\n",
    "def extract_weight(caption):\n",
    "    weight = None\n",
    "    # Find the substring within square brackets\n",
    "    start_index = caption.find('>')\n",
    "    end_index = caption.find('=')\n",
    "    if start_index != -1:\n",
    "        if end_index != -1:\n",
    "            weight_str = caption[start_index+1:end_index].strip()\n",
    "        else:\n",
    "            weight_str = caption[start_index+1:].strip()\n",
    "        if weight_str:\n",
    "            # Extract the numbers after '>'\n",
    "            weight_str = weight_str.split()[0]  # Lấy số đầu tiên sau dấu space\n",
    "            weight_str = weight_str.replace('lbs', '')  # Loại bỏ từ 'lbs'\n",
    "            if weight_str.isdigit():\n",
    "                weight = int(weight_str)\n",
    "    return weight\n",
    "\n",
    "\n",
    "# Apply the functions to create new columns\n",
    "df['Gender'] = df['Caption'].apply(extract_gender)\n",
    "df['Age'] = df['Caption'].apply(extract_age)\n",
    "df['Height'] = df['Caption'].apply(extract_height)\n",
    "df['Weight'] = df['Caption'].apply(extract_weight)\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "df.to_csv('new_image_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caculate BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated with BMI successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('new_image_data.csv')\n",
    "\n",
    "# Function to convert height from feet and inches to meters\n",
    "def convert_height_to_meters(height):\n",
    "    if \"'\" in height or \"’\" in height:\n",
    "        height_parts = height.replace(\"’\", \"'\").split(\"'\")  # Thay dấu ’ thành ' và split theo dấu '\n",
    "        feet = float(height_parts[0])\n",
    "        if len(height_parts) > 1:\n",
    "            inches_str = height_parts[1].replace(\"\\\"\", \"\").strip()  # Xóa dấu \" và khoảng trắng\n",
    "            if inches_str.isdigit():\n",
    "                inches = float(inches_str)\n",
    "            else:\n",
    "                inches = 0.0\n",
    "        else:\n",
    "            inches = 0.0\n",
    "        total_inches = feet * 12 + inches\n",
    "        height_meters = total_inches * 0.0254  # Convert inches to meters\n",
    "        return height_meters\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Function to calculate BMI\n",
    "def calculate_bmi(height, weight):\n",
    "    if height is not None and weight is not None:\n",
    "        height_m = convert_height_to_meters(height)\n",
    "        weight_kg = weight * 0.453592  # Convert weight from lbs to kg\n",
    "        if height_m:\n",
    "            bmi = weight_kg / (height_m ** 2)  # Calculate BMI\n",
    "            return bmi\n",
    "    return None\n",
    "\n",
    "# Calculate BMI and add a new column 'BMI'\n",
    "df['BMI'] = df.apply(lambda row: calculate_bmi(row['Height'], row['Weight']), axis=1)\n",
    "\n",
    "\n",
    "# Save the DataFrame to the same CSV file, overwriting it\n",
    "df.to_csv('new_image_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file updated with BMI successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file updated with BMI classification successfully!\n"
     ]
    }
   ],
   "source": [
    "# Function to classify BMI based on gender\n",
    "def classify_bmi_with_gender(bmi, gender):\n",
    "    if bmi is not None and gender is not None:\n",
    "        if gender == 'M':\n",
    "            if bmi < 18.5:\n",
    "                return 'Underweight'\n",
    "            elif 18.5 <= bmi < 24.9:\n",
    "                return 'Normal weight'\n",
    "            elif 24.9 <= bmi < 29.9:\n",
    "                return 'Overweight'\n",
    "            else:\n",
    "                return 'Obese'\n",
    "        elif gender == 'F':\n",
    "            if bmi < 18.5:\n",
    "                return 'Underweight'\n",
    "            elif 18.5 <= bmi < 24.9:\n",
    "                return 'Normal weight'\n",
    "            elif 24.9 <= bmi < 29.9:\n",
    "                return 'Overweight'\n",
    "            else:\n",
    "                return 'Obese'\n",
    "    return None\n",
    "\n",
    "# Apply the function to create a new column 'BMI Classification with Gender'\n",
    "df['BMI Classification with Gender'] = df.apply(lambda row: classify_bmi_with_gender(row['BMI'], row['Gender']), axis=1)\n",
    "\n",
    "\n",
    "# Save the DataFrame to the same CSV file, overwriting it\n",
    "df.to_csv('new_image_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file updated with BMI classification successfully!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
